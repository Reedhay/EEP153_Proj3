{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52afa108-de3a-4efd-9e97-74c3b27d0862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: CFEDemands>=0.6.3.dev0 in /srv/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.6.4.dev0)\n",
      "Requirement already satisfied: ConsumerDemands>=0.4.3.dev0 in /srv/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.4.3.dev0)\n",
      "Requirement already satisfied: matplotlib>=3.3.4 in /srv/conda/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (3.10.1)\n",
      "Requirement already satisfied: numpy>=1.21.5 in /srv/conda/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (2.2.4)\n",
      "Requirement already satisfied: pandas>=1.3.5 in /srv/conda/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (2.2.3)\n",
      "Requirement already satisfied: plotly>=5.1.0 in /srv/conda/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (6.0.1)\n",
      "Requirement already satisfied: eep153_tools>=0.11 in /srv/conda/lib/python3.11/site-packages (from -r requirements.txt (line 25)) (0.12.4)\n",
      "Requirement already satisfied: python-gnupg in /srv/conda/lib/python3.11/site-packages (from -r requirements.txt (line 26)) (0.5.4)\n",
      "Requirement already satisfied: gspread_pandas>=3.3 in /srv/conda/lib/python3.11/site-packages (from -r requirements.txt (line 28)) (3.3.0)\n",
      "Requirement already satisfied: scikit-learn in /srv/conda/lib/python3.11/site-packages (from -r requirements.txt (line 30)) (1.6.0)\n",
      "Requirement already satisfied: xarray in /srv/conda/lib/python3.11/site-packages (from -r requirements.txt (line 31)) (2025.1.1)\n",
      "Requirement already satisfied: scipy>=1.7.3 in /srv/conda/lib/python3.11/site-packages (from CFEDemands>=0.6.3.dev0->-r requirements.txt (line 5)) (1.14.1)\n",
      "Requirement already satisfied: importlib_metadata>=6.7.0 in /srv/conda/lib/python3.11/site-packages (from CFEDemands>=0.6.3.dev0->-r requirements.txt (line 5)) (8.6.1)\n",
      "Requirement already satisfied: fsspec in /srv/conda/lib/python3.11/site-packages (from CFEDemands>=0.6.3.dev0->-r requirements.txt (line 5)) (2025.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /srv/conda/lib/python3.11/site-packages (from matplotlib>=3.3.4->-r requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /srv/conda/lib/python3.11/site-packages (from matplotlib>=3.3.4->-r requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /srv/conda/lib/python3.11/site-packages (from matplotlib>=3.3.4->-r requirements.txt (line 10)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /srv/conda/lib/python3.11/site-packages (from matplotlib>=3.3.4->-r requirements.txt (line 10)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /srv/conda/lib/python3.11/site-packages (from matplotlib>=3.3.4->-r requirements.txt (line 10)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /srv/conda/lib/python3.11/site-packages (from matplotlib>=3.3.4->-r requirements.txt (line 10)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /srv/conda/lib/python3.11/site-packages (from matplotlib>=3.3.4->-r requirements.txt (line 10)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /srv/conda/lib/python3.11/site-packages (from matplotlib>=3.3.4->-r requirements.txt (line 10)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/lib/python3.11/site-packages (from pandas>=1.3.5->-r requirements.txt (line 20)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /srv/conda/lib/python3.11/site-packages (from pandas>=1.3.5->-r requirements.txt (line 20)) (2025.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /srv/conda/lib/python3.11/site-packages (from plotly>=5.1.0->-r requirements.txt (line 23)) (1.33.0)\n",
      "Requirement already satisfied: gspread<6,>=5.0.0 in /srv/conda/lib/python3.11/site-packages (from gspread_pandas>=3.3->-r requirements.txt (line 28)) (5.12.4)\n",
      "Requirement already satisfied: decorator in /srv/conda/lib/python3.11/site-packages (from gspread_pandas>=3.3->-r requirements.txt (line 28)) (5.1.1)\n",
      "Requirement already satisfied: google-auth in /srv/conda/lib/python3.11/site-packages (from gspread_pandas>=3.3->-r requirements.txt (line 28)) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /srv/conda/lib/python3.11/site-packages (from gspread_pandas>=3.3->-r requirements.txt (line 28)) (1.2.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /srv/conda/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 30)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /srv/conda/lib/python3.11/site-packages (from scikit-learn->-r requirements.txt (line 30)) (3.6.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /srv/conda/lib/python3.11/site-packages (from google-auth->gspread_pandas>=3.3->-r requirements.txt (line 28)) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /srv/conda/lib/python3.11/site-packages (from google-auth->gspread_pandas>=3.3->-r requirements.txt (line 28)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /srv/conda/lib/python3.11/site-packages (from google-auth->gspread_pandas>=3.3->-r requirements.txt (line 28)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /srv/conda/lib/python3.11/site-packages (from google-auth-oauthlib->gspread_pandas>=3.3->-r requirements.txt (line 28)) (2.0.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /srv/conda/lib/python3.11/site-packages (from importlib_metadata>=6.7.0->CFEDemands>=0.6.3.dev0->-r requirements.txt (line 5)) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->-r requirements.txt (line 10)) (1.17.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /srv/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth->gspread_pandas>=3.3->-r requirements.txt (line 28)) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /srv/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas>=3.3->-r requirements.txt (line 28)) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /srv/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas>=3.3->-r requirements.txt (line 28)) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas>=3.3->-r requirements.txt (line 28)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas>=3.3->-r requirements.txt (line 28)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas>=3.3->-r requirements.txt (line 28)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas>=3.3->-r requirements.txt (line 28)) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "#run this to install the package\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ddb2f16-bf37-469f-8d45-895edaff4d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from eep153_tools.sheets import read_sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcffa1d-2810-4538-bd06-87b59b559c11",
   "metadata": {},
   "source": [
    "## **From Sheet to DataFrame to Regression Object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613730a6-ecda-4ec7-9dfc-e7ff56e58c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "US_Data = \"1OWluIYUGkmR6iFgSzJJa2ikEqqMT6BHbsKZyip236HU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8631971a-e61f-42ae-889c-8a05e4439896",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = read_sheets(US_Data,sheet='Food Expenditures 2021')\n",
    "x[\"j\"] = x[\"food_name\"]\n",
    "x = x.set_index(['i','t','m','j'])[\"grams\"].squeeze()\n",
    "\n",
    "# Household characteristics\n",
    "d = read_sheets(US_Data,sheet=\"Household Characteristics 2021\")\n",
    "d.columns.name = 'k'\n",
    "d[\"sex\"] = d[\"sex\"].map({\"Female\": 1, \"Male\": 0})\n",
    "d['log_household'] = np.log(d['HH_size'])\n",
    "d.drop(\"HH_size\", axis= 1, inplace=True)\n",
    "\n",
    "# Fill blanks with zeros\n",
    "d = d.replace(np.nan,0)\n",
    "\n",
    "# Expenditures x may have duplicate columns\n",
    "x = x.T.groupby(['i','t','m','j']).sum()\n",
    "x = x.replace(0,np.nan) # Replace zeros with missing\n",
    "\n",
    "# Take logs of expenditures; call this y\n",
    "y = np.log(x)\n",
    "d.set_index(['i','t','m'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6060bfc-8360-4480-a504-54811d6ef9dc",
   "metadata": {},
   "source": [
    "### Filter Data Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0b18cb-d86b-410b-b8c5-31d041d98dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_final: (85881,)\n",
      "Shape of d_final: (6711, 3)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Filter goods by frequency (top 400)\n",
    "food_counts = y.groupby('j').count()\n",
    "top_foods = food_counts.sort_values(ascending=False).head(350).index\n",
    "\n",
    "# Filter x and y to only include these popular goods.\n",
    "x_filtered = x[x.index.get_level_values('j').isin(top_foods)]\n",
    "y_filtered = y[y.index.get_level_values('j').isin(top_foods)]\n",
    "\n",
    "# Step 2: Instead of random sampling, use all households present in y_filtered.\n",
    "# Get all unique household ids from y_filtered.\n",
    "common_ids = y_filtered.index.get_level_values('i').unique()\n",
    "\n",
    "# Filter y and d to keep only households in common_ids.\n",
    "# (This is effectively taking the full data that has corresponding expenditures.)\n",
    "y_final = y_filtered[y_filtered.index.get_level_values('i').isin(common_ids)]\n",
    "d_final = d[d.index.get_level_values('i').isin(common_ids)]\n",
    "\n",
    "# Filter y and d to match\n",
    "# sample_ids = y_filtered.index.get_level_values('i').unique().to_series().sample(1750, random_state=42)\n",
    "# y_sample = y_filtered[y_filtered.index.get_level_values('i').isin(sample_ids)]\n",
    "# d_sample = d[d.index.get_level_values('i').isin(sample_ids)]\n",
    "\n",
    "# Final checks\n",
    "print(\"Shape of y_final:\", y_final.shape)\n",
    "print(\"Shape of d_final:\", d_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66610f7d-8ffe-454d-afaf-a53f068001ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i       t     m    j                                                        \n",
       "130378  2021  USA  Caesar dressing                                              1.589235\n",
       "                   Cheese, parmesan, dry grated                                 0.732368\n",
       "                   Chicken, ns as to part and cooking method, skin not eaten    5.136386\n",
       "                   Coffee, brewed                                               6.396930\n",
       "                   Coffee, instant, reconstituted                               5.703782\n",
       "                                                                                  ...   \n",
       "142310  2021  USA  Mayonnaise, regular                                          2.639057\n",
       "                   Potato chips, plain                                          2.995732\n",
       "                   Sugar substitute, sucralose, powder                          0.000000\n",
       "                   Water, bottled, plain                                        6.201523\n",
       "                   Wine, red                                                    0.631272\n",
       "Name: grams, Length: 85881, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f24cca5-eb43-4f5f-bb5c-2e77f00039c2",
   "metadata": {},
   "source": [
    "## **Build Price Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a7825fd-09c0-4ec7-a802-cdd35bed90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add price data\n",
    "p = pd.read_csv(\"proj3_min_cost_data - prices.csv\")\n",
    "\n",
    "# Change column names to actual unit values\n",
    "p[\"u\"] = \"Kg\"\n",
    "\n",
    "p[\"m\"] = \"USA\"\n",
    "\n",
    "# Adjust price to per Kg from per g\n",
    "p[\"price\"] = p[\"price\"] * 10\n",
    "\n",
    "# Filter for only 2017/2018 prices\n",
    "p = p[p[\"t\"] == \"2017/2018\"]\n",
    "\n",
    "# Change price data from 2017/2018 to 2021 using avg US CPIs in 2017/2018 and 2021\n",
    "cpi_2021 = 271.0\n",
    "cpi_2018 = 250.0\n",
    "p[\"price\"] = p[\"price\"] * (cpi_2021/cpi_2018)\n",
    "\n",
    "p[\"t\"] = \"2021\"\n",
    "\n",
    "\n",
    "codes = pd.read_csv(\"proj3_min_cost_data - recipes.csv\")\n",
    "\n",
    "codes = codes[[\"parent_foodcode\", \"parent_desc\"]]\n",
    "c = codes.groupby(\"parent_foodcode\").first()\n",
    "c.rename(columns = {\"parent_foodcode\": \"j\"})\n",
    "p = p.join(c, on=\"j\")\n",
    "p_with_j = p # use later on for nutrition data\n",
    "p = p.drop(\"j\", axis=1)\n",
    "p = p.rename(columns = {\"parent_desc\":\"j\"})\n",
    "\n",
    "# Now prices\n",
    "p = p.set_index(['t','m','j','u'])\n",
    "\n",
    "# Compute medians of prices for particular time, place and unit\n",
    "p = p.groupby(['t','m','j','u']).median()\n",
    "\n",
    "# Just keep metric units\n",
    "p = p.xs('Kg',level=\"u\").squeeze().unstack('j')\n",
    "# Identify the common keys between x_filtered.index.levels[-1] and p.columns\n",
    "common_keys = p.columns.intersection(x_filtered.index.levels[-1])\n",
    "\n",
    "# Now subset p with these keys and transpose the result.\n",
    "p = p[common_keys].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eca203-fe3b-45b1-a501-ecf725de30ce",
   "metadata": {},
   "source": [
    "## **Run Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba2d7a12-bbf6-45ab-b20d-66222d41a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cfe import Regression\n",
    "\n",
    "# Run the regression\n",
    "result = Regression(y=y_final, d=d_final, compute_se=False, rectify=False, \n",
    "                    min_obs=10, min_prop_items=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571293ec-07af-4bb1-9f05-08b09c92b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = result.predicted_expenditures()\n",
    "predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fec065-139b-4a56-8bf5-8726aab26727",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create DataFrame of actual vs predicted log expenditures\n",
    "df = pd.DataFrame({\n",
    "    'y': y_final,\n",
    "    'yhat': result.get_predicted_log_expenditures()\n",
    "})\n",
    "\n",
    "# Drop missing values (some may not match if data was trimmed)\n",
    "df = df.dropna()\n",
    "\n",
    "# Plot\n",
    "df.plot.scatter(x='yhat', y='y', alpha=0.4, figsize=(6, 6))\n",
    "plt.title(\"Predicted vs Actual Log Expenditures\")\n",
    "plt.xlabel(\"Predicted log expenditure (ŷ)\")\n",
    "plt.ylabel(\"Actual log expenditure (y)\")\n",
    "plt.grid(True)\n",
    "plt.axis(\"equal\")  # force square axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f403e727-890a-47c9-838e-d6a259907b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = result.graph_beta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54ec5e5-1b72-408c-8418-725ebd7d1c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_beta().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e499d2fd-3f01-4bd2-a22d-9dcd36816f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "foods_in_regression = result.beta.index.get_level_values('j').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001488bb-5edb-4e40-b716-805d1be1b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_gamma().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28674741-afe6-4547-bda0-45baf26ab283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "gamma = result.get_gamma()\n",
    "gamma_sorted = gamma.sort_values(by=\"Constant\", ascending=False)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=gamma_sorted, x=\"Constant\", y=\"j\")\n",
    "plt.xlabel(\"Gamma (Constant)\")\n",
    "plt.ylabel(\"Food Item\")\n",
    "plt.title(\"Gamma Constants by Food Item\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b03b24-8f4d-4200-bed7-524a179b4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = result.get_w().plot.hist(bins=100,density=True)\n",
    "result.get_w().plot.kde(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4dbead-2f11-4408-b918-6bfc4476698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = result.get_w()[(result.get_w() > -10) & (result.get_w() < 10)].plot.hist(bins=100,density=True)\n",
    "result.get_w()[(result.get_w() > -10) & (result.get_w() < 10)].plot.kde(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf2377-53d0-4ddb-a4c8-5b8ef8710bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = result.get_gamma()\n",
    "gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6260457-00bb-4bcb-9aa0-1d7069203589",
   "metadata": {},
   "source": [
    "## Saving Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f71102-3e13-4eb9-b77d-1972f4281e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_pickle('us_estimates_2021.rgsn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f089f549-6549-4e96-bbf4-5a184041efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cfe\n",
    "\n",
    "# Load the result back into memory\n",
    "result = cfe.regression.read_pickle('us_estimates_2021.rgsn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae5e38-db12-48cf-8694-bd7d6966ddd9",
   "metadata": {},
   "source": [
    "## **Demand and Utility**\n",
    "\n",
    "Having estimated the demand system, we can examine the implied demand curves.\n",
    "\n",
    "## Budgets\n",
    "Get food budget for all households, then find median budget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a596c31d-3aa8-47fd-b4c2-dee49f027e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "xhat = result.predicted_expenditures()\n",
    "\n",
    "# Total food expenditures per household\n",
    "xbar = xhat.groupby(['i','t','m']).sum()\n",
    "\n",
    "# Reference budget\n",
    "xref = xbar.quantile(0.5)  # Household at 0.5 quantile is median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f31c310-8cf6-4341-88fb-ca0e008a82e9",
   "metadata": {},
   "source": [
    "**Reference Prices**\n",
    "  \n",
    "Choose reference prices. Here we’ll choose a particular year, and average prices across markets. If you wanted to focus on particular market you’d do this differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa0105b-0c0a-41dd-900a-2ec53427f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference prices chosen from a particular time; average across place.\n",
    "# These are prices per kilogram:\n",
    "pbar = p.mean(axis=1)\n",
    "\n",
    "# Instead of directly indexing with result.beta.index (which fails for missing keys),\n",
    "# reindex pbar to have the same index as result.beta and fill missing prices with 1.\n",
    "pbar = pbar.reindex(result.beta.index, fill_value=1)\n",
    "\n",
    "# (Optional) Get the common keys, which should be all keys in result.beta.index:\n",
    "common_keys = pbar.index.intersection(result.beta.index)\n",
    "pbar = pbar.loc[common_keys]\n",
    "\n",
    "# Replace any remaining missing values with 1.\n",
    "pbar = pbar.replace(np.nan, 1)\n",
    "\n",
    "# Finally, define a function to change the price of a single good in the price vector.\n",
    "def my_prices(p0, j, p=pbar):\n",
    "    \"\"\"\n",
    "    Change price of the jth good to p0, holding all other prices fixed.\n",
    "    \n",
    "    Parameters:\n",
    "      p0 : float\n",
    "          New price for the jth good.\n",
    "      j : label\n",
    "          Identifier for the good (must be present in p).\n",
    "      p : pd.Series\n",
    "          Price vector (default is pbar).\n",
    "    \n",
    "    Returns:\n",
    "      pd.Series : A new price vector with the updated value.\n",
    "    \"\"\"\n",
    "    p = p.copy()\n",
    "    p.loc[j] = p0\n",
    "    return p\n",
    "\n",
    "common_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e955e5d1-52fe-4860-8513-d2cfbaa79306",
   "metadata": {},
   "source": [
    "## **Demand Curve for One Food**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa6987-f381-492c-831e-29362461f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_demand_curve(good):\n",
    "    \"\"\"\n",
    "    Plot the demand curve for a given good over a range of price scales.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    good : str\n",
    "        The common key (food identifier) for which you want the demand curve,\n",
    "        e.g. \"Banana, raw\".\n",
    "        \n",
    "    Global Variables (should be defined before calling this function):\n",
    "      pbar         : pd.Series of reference prices (indexed by food identifier)\n",
    "      result       : an object with a demands() method and attribute beta.index.\n",
    "      xref         : reference expenditure vector (e.g., median household expenditures)\n",
    "      xbar         : household total expenditures used to compute quantiles.\n",
    "      my_prices()  : function that returns a modified price vector.\n",
    "    \"\"\"\n",
    "    # Suppress warnings about negative beta values\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Setting negative values of beta to zero\")\n",
    "    \n",
    "    # Reindex pbar so that it has the same index as result.beta.index, filling missing keys with 1.\n",
    "    pbar_local = pbar.reindex(result.beta.index, fill_value=1)\n",
    "    \n",
    "    # Define a range of scale factors: vary prices from 50% to 200% of the reference price.\n",
    "    scale = np.linspace(0.5, 2, 20)\n",
    "    \n",
    "    # Compute demand for the given good at different price levels.\n",
    "    # Wrap the list comprehensions in a warnings.catch_warnings block to suppress any warnings during computation.\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\"Setting negative values of beta to zero\")\n",
    "        median_demand = [result.demands(xref, my_prices(pbar_local[good] * s, good, pbar_local))[good]\n",
    "                         for s in scale]\n",
    "        demand_q25 = [result.demands(xbar.quantile(0.25), my_prices(pbar_local[good] * s, good, pbar_local))[good]\n",
    "                      for s in scale]\n",
    "        demand_q75 = [result.demands(xbar.quantile(0.75), my_prices(pbar_local[good] * s, good, pbar_local))[good]\n",
    "                      for s in scale]\n",
    "    \n",
    "    # Create the plot.\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(median_demand, scale, marker=\"o\", label=\"Median Budget\")\n",
    "    plt.plot(demand_q25, scale, marker=\"s\", label=\"25th Percentile Budget\")\n",
    "    plt.plot(demand_q75, scale, marker=\"^\", label=\"75th Percentile Budget\")\n",
    "    \n",
    "    # Add axis labels, title, legend, and grid.\n",
    "    plt.xlabel(f\"Quantities of {good} Demanded\")\n",
    "    plt.ylabel(f\"Price (relative to base of {pbar_local[good]:.2f})\")\n",
    "    plt.title(f\"Demand Curve for {good}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d74ca2-4c2c-4d91-b997-6c3801c543e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demand_curve('Banana, raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d165a-3b1e-4a7f-b5e4-b2bcdd809ca1",
   "metadata": {},
   "source": [
    "## **Demand Curve for More than One good**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dffe8f-6206-4b6b-932d-0fe3392f0df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_demand_curves(goods):\n",
    "    \"\"\"\n",
    "    Plot demand curves for multiple goods over a range of price scales.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    goods : tuple or list of str\n",
    "        The food identifiers (common keys) for which you want to plot demand curves.\n",
    "        For example: ('Banana, raw', 'Apple, raw', 'Milk, whole')\n",
    "    \n",
    "    Global variables required:\n",
    "      - pbar: pd.Series with reference prices (indexed by food identifiers)\n",
    "      - result: an object with methods demands() and attribute beta.index\n",
    "      - xref: reference expenditure vector (e.g., median expenditures)\n",
    "      - xbar: household total expenditures (used for quantile calculations)\n",
    "      - my_prices(): function to adjust the price vector\n",
    "    \"\"\"\n",
    "    # Suppress specific warnings (from consumerdemands._utils)\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Setting negative values of beta to zero\")\n",
    "    \n",
    "    # Ensure pbar covers all keys in result.beta.index; fill missing values with 1.\n",
    "    pbar_local = pbar.reindex(result.beta.index, fill_value=1)\n",
    "    \n",
    "    # Define a range of scale factors to vary the price from 50% to 200% of reference.\n",
    "    scale = np.linspace(0.5, 2, 20)\n",
    "    \n",
    "    # Create a new figure for the plot.\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Loop over each good in the input tuple/list.\n",
    "    for good in goods:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"Setting negative values of beta to zero\")\n",
    "            # Compute the demand for the given good at various price levels.\n",
    "            median_demand = [result.demands(xref, my_prices(pbar_local[good] * s, good, pbar_local))[good]\n",
    "                             for s in scale]\n",
    "            demand_q25 = [result.demands(xbar.quantile(0.25), my_prices(pbar_local[good] * s, good, pbar_local))[good]\n",
    "                          for s in scale]\n",
    "            demand_q75 = [result.demands(xbar.quantile(0.75), my_prices(pbar_local[good] * s, good, pbar_local))[good]\n",
    "                          for s in scale]\n",
    "        \n",
    "        # Plot each demand curve with distinct line styles and markers.\n",
    "        plt.plot(median_demand, scale,\n",
    "                 label=f\"{good} (Median Budget)\")\n",
    "        plt.plot(demand_q25, scale,\n",
    "                 label=f\"{good} (25th Percentile Budget)\")\n",
    "        plt.plot(demand_q75, scale,\n",
    "                 label=f\"{good} (75th Percentile Budget)\")\n",
    "    \n",
    "    # Add labels, title, legend, and grid.\n",
    "    plt.xlabel(\"Quantity Demanded\")\n",
    "    # This label uses the base reference price of the first good in the list for display.\n",
    "    plt.ylabel(f\"Price (relative to base of {pbar_local[goods[0]]:.2f})\")\n",
    "    plt.title(\"Demand Curves for Selected Goods\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f5dec-3a0c-4412-87ea-f371fad9199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "plot_demand_curves(('Banana, raw', 'Milk, whole'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a70aa3-468e-4f93-a051-3caef231a18d",
   "metadata": {},
   "source": [
    "## **Engle Curves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9824d19d-78b3-446e-a1ce-a7ca35e8f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define scale, say we vary the budget from 50% to 200% of xref\n",
    "scale = np.linspace(0.5, 2.0, 20)\n",
    "\n",
    "# Now plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.log(scale*xref),\n",
    "        [result.expenditures(s*xref, pbar)/(s*xref) for s in scale])\n",
    "ax.set_xlabel(f'log budget (relative to base of {xref:.0f})')\n",
    "ax.set_ylabel('Expenditure share')\n",
    "ax.set_title('Engel Curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef4b3d-442a-4283-9da6-ddac10e51189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_engel_curves(interesting_goods, xref, scale, pbar, result):\n",
    "    \"\"\"\n",
    "    Plot Engel curves for a list of specified goods.\n",
    "    \n",
    "    Parameters:\n",
    "      interesting_goods: list of str\n",
    "          A list of goods (by food name or id) for which to plot the curve.\n",
    "      xref: float\n",
    "          The base household budget.\n",
    "      scale: array-like\n",
    "          A list or array of scaling factors for the budget (e.g., np.linspace(0.5,2,20)).\n",
    "      pbar: pandas.Series or DataFrame\n",
    "          The reference prices for foods. The index should contain the goods' names.\n",
    "      result:\n",
    "          An object with a method `expenditures(budget, pbar)` that returns a pandas Series \n",
    "          with expenditures for each food (keys corresponding to food names).\n",
    "    \n",
    "    Returns:\n",
    "      fig, ax : matplotlib Figure and Axes objects.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Loop over each requested good and calculate its expenditure share at each budget.\n",
    "    for good in interesting_goods:\n",
    "        shares = []\n",
    "        for s in scale:\n",
    "            budget = s * xref  # Scale the base budget by s.\n",
    "            exp_series = result.expenditures(budget, pbar)\n",
    "            # Check if the good exists in the returned series\n",
    "            if good in exp_series.index:\n",
    "                share = exp_series[good] / budget\n",
    "            else:\n",
    "                # Print a warning if the good is not found and set the share to NaN.\n",
    "                print(f\"Warning: '{good}' not found in expenditure series at budget {budget:.2f}\")\n",
    "                share = np.nan\n",
    "            shares.append(share)\n",
    "            \n",
    "        # Plot the Engel curve for this good using log(s * xref) on x-axis.\n",
    "        ax.plot(np.log(scale * xref), shares, label=good)\n",
    "    \n",
    "    # Set axis labels and title.\n",
    "    ax.set_xlabel(f'Log Budget (relative to base of {xref:.0f})', fontsize=12)\n",
    "    ax.set_ylabel('Expenditure Share', fontsize=12)\n",
    "    ax.set_title(\"Engel Curves for Selected Goods\", fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=8, loc='best')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944c0a1-364e-426a-ab2e-777fe5908abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Define your variables appropriately\n",
    "xref = 3272  # example base budget\n",
    "scale = np.linspace(0.5, 2, 20)  # example scale factors\n",
    "# pbar and result must be defined elsewhere in your code:\n",
    "# For example, pbar could be a pandas Series keyed by food names,\n",
    "# and result should be an object with a method expenditures(budget, pbar).\n",
    "\n",
    "interesting_goods = [\"Avocado, raw\", \"Banana, raw\", \"Water, tap\", \"Apple, raw\", \"Onions, raw\"]\n",
    "\n",
    "fig, ax = plot_engel_curves(interesting_goods, xref, scale, pbar, result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5ca875-b53f-48a6-89a2-43abe047d965",
   "metadata": {},
   "source": [
    "## **Indirect Utility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d580287-9e0d-4a9e-af6b-df0c4b4c6c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(scale*xref,[result.indirect_utility(s*xref,pbar) for s in scale])\n",
    "ax.set_xlabel(f'Indirect Utility (Budget relative to base of {xref:.0f}')\n",
    "ax.set_ylabel(f'Utility')\n",
    "ax.set_title('Indirect Utility Function')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63d362-d16c-4ec6-b0cf-9ae1133358f6",
   "metadata": {},
   "source": [
    "# **[A] Nutritional Data**\n",
    "### Step 1: Acquire DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f46450-5c38-4d37-af05-8050bd684b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat.unstack('j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2b651-4748-4c25-bc94-a30cc06d41d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2bb0d-c8a9-44d5-a4b7-09f68af23902",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_new = pd.read_csv(\"proj3_min_cost_data - prices.csv\")\n",
    "p_new[\"u\"] = \"Kg\"\n",
    "\n",
    "p_new[\"m\"] = \"USA\"\n",
    "\n",
    "p_new[\"price\"] = p_new[\"price\"] * 10\n",
    "\n",
    "p_new = p_new[p_new[\"t\"] == \"2017/2018\"]\n",
    "\n",
    "\n",
    "# Change price data from 2017/2018 to 2021 using avg US CPIs in 2017/2018 and 2021\n",
    "cpi_2021 = 271.0\n",
    "cpi_2018 = 250.0\n",
    "p_new[\"price\"] = p_new[\"price\"] * (cpi_2021/cpi_2018)\n",
    "\n",
    "p_new[\"t\"] = \"2021\"\n",
    "\n",
    "p_new = p_new.join(c, on=\"j\") \n",
    "p_new = p_new.drop(\"j\", axis=1)\n",
    "p_new = p_new.drop(\"t\", axis=1)\n",
    "p_new = p_new.drop(\"u\", axis=1)\n",
    "p_new = p_new.rename(columns = {\"parent_desc\":\"j\"})\n",
    "\n",
    "p_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c146ae7b-dbfe-48db-9674-9bb83b18a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pivot = p_new.pivot_table(\n",
    "    index=[\"m\"],   # or [\"m\", \"t\"] if you prefer that order\n",
    "    columns=\"j\",\n",
    "    values=\"price\",\n",
    "    aggfunc=\"sum\"      # or another aggregation if you have duplicates\n",
    ")\n",
    "\n",
    "p_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72773aa-c559-4bc4-9114-612acd24f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expenditures divided by prices/kg gives quantities in kgs...\n",
    "xhat_unstacked = xhat.unstack('j')\n",
    "xhat_unstacked_aligned = xhat_unstacked.reindex(index=p_pivot.index, columns=p_pivot.columns)\n",
    "common_columns = xhat_unstacked_aligned.columns.intersection(p_pivot.columns)\n",
    "common_index = xhat_unstacked_aligned.index.intersection(p_pivot.index)\n",
    "\n",
    "p_pivot_aligned = p_pivot.loc[common_index, common_columns]\n",
    "\n",
    "qhat = (xhat_unstacked/p_pivot_aligned).dropna(how='all')\n",
    "\n",
    "# Drop missing columns\n",
    "qhat = qhat.loc[:,qhat.count()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ad863-4d32-48c0-a608-65a16008cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients = pd.read_csv(\"proj3_min_cost_data - nutrients.csv\")\n",
    "recipes = pd.read_csv(\"proj3_min_cost_data - recipes.csv\")\n",
    "\n",
    "# from fndds diet problem: normalize weights to percentage terms. \n",
    "recipes['ingred_wt'] = recipes['ingred_wt']/recipes.groupby(['parent_foodcode'])['ingred_wt'].transform(\"sum\")\n",
    "\n",
    "# we're going to extend the recipes data frame to include the nutrient profiles of its ingredients (in 100g)\n",
    "df = recipes.merge(nutrients, how=\"left\", on=\"ingred_code\")\n",
    "\n",
    "# multiply all nutrients per 100g of an ingredient by the weight of that ingredient in a recipe.\n",
    "numeric_cols = list(df.select_dtypes(include=[\"number\"]).columns)\n",
    "numeric_cols.remove(\"ingred_wt\")\n",
    "df[numeric_cols] = df[numeric_cols].mul(df[\"ingred_wt\"], axis=0)\n",
    "df = df.rename(columns={'parent_desc': 'j'})\n",
    "\n",
    "# sum nutrients of food codes (over the multiple ingredients)\n",
    "# python tip: one can merge dictionaries dict1 dict2 using **, that is: dict_merge = {**dict1, **dict2}. \n",
    "#The ** effectively \"unpacks\" the key value pairs in each dictionary\n",
    "df = df.groupby('j').agg({**{col: \"sum\" for col in numeric_cols},\n",
    "                                        \"j\": \"first\"})\n",
    "df.drop(\"parent_foodcode\", axis = 1, inplace=True)\n",
    "df.drop(\"ingred_code\", axis = 1, inplace=True)\n",
    "df.drop(\"j\", axis = 1, inplace=True)\n",
    "\n",
    "df.index.name = \"j\"\n",
    "\n",
    "fct = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49094306-549e-48d9-aac8-6d213e9cc7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fct.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c8b0d-6040-4ba9-be00-8d999103d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qhat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7abb2-2781-4fb6-864a-33e7dc7456d3",
   "metadata": {},
   "source": [
    "## **Map predicted quantities into nutrients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d8a567-6e33-4a65-af2c-2dae769e7b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use = fct.index.intersection(qhat.columns)\n",
    "\n",
    "\n",
    "nutrients = qhat[use]@fct.loc[use,:]\n",
    "nutrients.mean()    # NB: Nutrients are for past /week/ for entire household. (Depends on dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672cdcea-5278-461d-9422-3d33a2cfc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdi = pd.read_csv(\"proj3_min_cost_data - rda_new.csv\")\n",
    "rdi[\"n\"] = rdi[\"Nutrient\"]\n",
    "rdi.drop(\"Nutrient\", axis = 1, inplace=True)\n",
    "rdi.drop(\"Nutrient Type\", axis = 1, inplace=True)\n",
    "rdi.drop(\"Unit\", axis = 1, inplace=True)\n",
    "rdi.drop(\"Constraint Type\", axis = 1, inplace=True)\n",
    "rdi = rdi.set_index(\"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7375e-d780-4016-b80f-6fdddb9c4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_sheets(US_Data,sheet=\"Household Characteristics 2021\")\n",
    "d.columns.name = 'k'\n",
    "d = d.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a5ab0c-8410-4aed-a416-dd0bc96f1a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age bins and labels\n",
    "bins = [0, 4, 9, 14, 19, 31, 51, 100]\n",
    "labels = ['00-03', '04-08', '09-13', '14-18', '19-30', '31-50', '51-99']\n",
    "\n",
    "# Assign age group based on bins\n",
    "d['age_group'] = pd.cut(d['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Create column name like \"Females 00-03\", \"Males 14-18\", etc.\n",
    "d['group'] = d['sex'] + 's ' + d['age_group'].astype(str)\n",
    "\n",
    "# Count each person as 1\n",
    "d['count'] = 1\n",
    "\n",
    "# Pivot the table to wide format: rows = (i, t, m), columns = group\n",
    "df_grouped = d.pivot_table(index=['i', 't', 'm'], columns='group', values='count',  aggfunc='sum', fill_value=0)\n",
    "\n",
    "# Flatten the column index\n",
    "df_grouped.columns.name = None\n",
    "df_grouped = df_grouped.reset_index()\n",
    "\n",
    "# Add log household size\n",
    "df_hsize = d.drop_duplicates(['i', 't', 'm'])[['i', 't', 'm', 'HH_size']]\n",
    "df_hsize['log HSize'] = np.log(df_hsize['HH_size'])\n",
    "\n",
    "# Merge back\n",
    "final_d = pd.merge(df_grouped, df_hsize.drop(columns='HH_size'), on=['i', 't', 'm'])\n",
    "\n",
    "final_d.set_index(['i','t','m'],inplace=True)\n",
    "final_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467eb358-022a-4503-bbb2-ebae1f0bc19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_d = final_d[rdi.columns.tolist()]\n",
    "\n",
    "hh_rdi = final_d@rdi.T\n",
    "hh_rwi = hh_rdi*7\n",
    "hh_rdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0decf9-decb-4c19-b12e-fba5f0a86ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match up nutrient names\n",
    "use_nutrients = nutrients.columns.intersection(hh_rwi.columns)\n",
    "\n",
    "nutrient_ratio = (nutrients[use_nutrients]/hh_rwi[use_nutrients]).dropna()\n",
    "\n",
    "nutrient_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593ec4d-fd72-4475-a45b-b213093f8995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nutrient_histograms(nutrient_df, nutrients, log_transform=True, offset=1, bins=50, figsize=(8, 4)):\n",
    "    \"\"\"\n",
    "    Plot histograms for one or more nutrients from a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "      nutrient_df : pandas.DataFrame\n",
    "          DataFrame containing nutrient measurements in separate columns.\n",
    "      nutrients : str or list\n",
    "          The column name(s) for the nutrient(s) to plot.\n",
    "      log_transform : bool (default True)\n",
    "          If True, plot the log(values + offset) so that the distribution is on a log scale.\n",
    "      offset : numeric (default 1)\n",
    "          Added to the raw value before taking the logarithm (to avoid log(0)).\n",
    "      bins : int (default 50)\n",
    "          Number of histogram bins.\n",
    "      figsize : tuple (default (10, 6))\n",
    "          Figure size; if multiple nutrients are provided, the function creates one plot per nutrient vertically.\n",
    "          \n",
    "    Returns:\n",
    "      fig : matplotlib.figure.Figure\n",
    "          The figure object containing the histogram(s).\n",
    "      axes : matplotlib.axes.Axes or array of Axes\n",
    "          The Axes object(s) for further customization.\n",
    "    \"\"\"\n",
    "    # If a single nutrient is passed as a string, convert to list.\n",
    "    if isinstance(nutrients, str):\n",
    "        nutrients = [nutrients]\n",
    "    \n",
    "    num_nutrients = len(nutrients)\n",
    "    \n",
    "    # Create a figure with one subplot per nutrient.\n",
    "    fig, axes = plt.subplots(num_nutrients, 1, figsize=(figsize[0], figsize[1]*num_nutrients))\n",
    "    \n",
    "    # If only one nutrient, axes is a single Axes object, so wrap it in a list.\n",
    "    if num_nutrients == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Loop over each nutrient and create its histogram.\n",
    "    for ax, nutrient in zip(axes, nutrients):\n",
    "        # Get the raw values and drop missing values.\n",
    "        values = nutrient_df[nutrient].dropna().values\n",
    "        \n",
    "        # Optionally transform the values using a log, with an offset to avoid issues at 0.\n",
    "        if log_transform:\n",
    "            plot_values = np.log(values + offset)\n",
    "            xlabel = f'log({nutrient} + {offset})'\n",
    "        else:\n",
    "            plot_values = values\n",
    "            xlabel = nutrient\n",
    "            \n",
    "        # Calculate the mean of the transformed values.\n",
    "        mean_val = plot_values.mean()\n",
    "        \n",
    "        # Plot the histogram with black bin borders.\n",
    "        n, bin_edges, patches = ax.hist(plot_values, bins=bins, edgecolor='black', alpha=0.7, label=f'Distribution of {nutrient}')\n",
    "        \n",
    "        # Draw a vertical dashed red line at the mean.\n",
    "        ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean = {mean_val:.2f}')\n",
    "        \n",
    "        # Label the axes and add a title for this subplot.\n",
    "        ax.set_xlabel(xlabel, fontsize=12)\n",
    "        ax.set_ylabel(\"Frequency\", fontsize=12)\n",
    "        ax.set_title(f\"Histogram of {nutrient}\", fontsize=14, fontweight='bold')\n",
    "        ax.legend(fontsize=10, loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffedd92-4495-47a7-982e-fcb9a97ac8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nutrient_histograms(nutrient_ratio, ['Vitamin C', 'Vitamin D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba295549-b636-4967-a194-abb93e1d9fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6692.000000\n",
      "mean        2.778606\n",
      "std        63.826337\n",
      "min         0.019050\n",
      "25%         1.131265\n",
      "50%         1.576772\n",
      "75%         2.230004\n",
      "max      5215.829030\n",
      "Name: Vitamin E, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(nutrient_ratio['Vitamin E'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
